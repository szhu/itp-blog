<html>
 <head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, user-scalable=no" />
  <link rel="stylesheet" href="posts.css" />
  <script defer="" src="posts.js"></script>

  <title>Tech, Media, Democracy Week 2</title>
 </head>
 <body>
  <section class="section section-level-0">
   <header class="section-header">Tech, Media, Democracy Week 2</header>
   <div class="section-content">
    <p>
     From my perspective, this week's readings are filled with many idealistic
     demands that are far from materializing. I doubt that many disagree with
     the principles listed. It's how to materialize them that's the problem.
    </p>
    <hr />
    <p>
     <i
      >“We Make the Media - a Recent Speech at Freedom of Speech Online
      2018”&nbsp;Ethan Zuckerman, 9 Dec. 2018.</i
     ><br /><i
      ><a
       href="https://ethanzuckerman.com/2018/12/09/we-make-the-media-a-recent-speech-at-freedom-of-speech-online-2018/"
       target="_blank"
       >https://ethanzuckerman.com/2018/12/09/we-make-the-media-a-recent-speech-at-freedom-of-speech-online-2018/</a
      ></i
     >
    </p>
    <ul>
     <li>
      Meta: This article felt like it covered many topics, due to it being a
      speech. It wish it was better organized in print form.
     </li>
     <li>
      The author makes a great point in the media has evolved, and isn't as
      static as we often see it to be. This makes sense, but I also understand
      why people feel powerless — it's because any one person's potential to
      cause that kind of change seems very slim.
     </li>
     <li>
      <i
       >"4 P's: Personal control, Plural in purpose, Public in spirit,
       Participatory in governance"</i
      >
     </li>
     <li><i>"LinkedIn doesn’t have much of a problem with hate speech"</i></li>
     <ul>
      <li>
       That's not true! I've seen plenty of hate speech on LinkedIn… comments
       from people using their real names, with their employer listed.
      </li>
     </ul>
    </ul>
    <p>
     <i
      >Kornbluh, Karen. “Three Steps to Help Treat America’s Debilitating
      Information Disorder.”&nbsp;Washington Post, The Washington Post, 13 Jan.
      2021.</i
     ><br /><i
      ><a
       href="https://www.washingtonpost.com/opinions/2021/01/13/three-steps-help-treat-americas-debilitating-information-disorder/"
       target="_blank"
       >https://www.washingtonpost.com/opinions/2021/01/13/three-steps-help-treat-americas-debilitating-information-disorder/</a
      ></i
     >
    </p>
    <ul>
     <li>
      <i
       >"First, clarify that what happens online is subject to the same legal
       standards as what happens in real life, update regulations and increase
       enforcement."</i
      >
     </li>
     <ul>
      <li>
       There's a lot to unpack in the word "same". In real life, you can shout
       "this is on fire" in a theater, or you can shout at a concert (referring
       to the song). These two utterances of the same expression have very
       different legal consequences. Which one should be applied to Twitter
       posts? A major problem with online platforms is that there's no
       context-dependent enforcement, but real-life policies are almost entirely
       context-dependent.
      </li>
     </ul>
     <li>
      <i
       >"Second, insist that the industry make a high-level commitment to
       democratic design — a so-called digital code of conduct. Each platform
       should also make its own individual implementation commitments to which
       it will be held accountable. The code would be designed by the companies
       but overseen and enforced by the FTC, and any violation of the code would
       be enforced as a consumer protection violation."</i
      >
     </li>
     <ul>
      <li>
       The problem is that the definition of what constitutes a "code of
       conduct" will vary. In fact, most online platforms can probably already
       claim that they have a code of conduct.
      </li>
      <li>
       Another problem is that if there is a need for unregulated content, users
       will go to the unregulated platforms if the main platforms become
       regulated. There's a joke about someone asking an ex to unblock them by
       writing that in the message of a Venmo payment. What constitutes a
       platform?
      </li>
      <li>
       If we are too lax about the definitions of "code of conduct" and
       "platform", then we end up with the current situation. If we are too
       strict, then we will inevitably stifle innovation.
      </li>
     </ul>
     <li>
      <i
       >"Third, we should create a new “PBS of the Internet” to strengthen our
       civic infrastructure and ensure a strong online supply of trustworthy,
       nonpartisan scientific and election information."</i
      >
     </li>
     <ul>
      <li>
       This also seems great in theory, but unfortunately is not concrete. Radio
       and TV were well suited to PBS, since the format and the limitation of
       the platforms were clear and stable. With the amount of technological
       progress we are currently making, this is not true for the Internet. A
       more apt Internet analog to PBS for TV/radio would be PBS of online
       video, PBS for podcasts, etc. And indeed, we have those already — PBS is
       on those platforms.
      </li>
      <li>
       <i
        >"Next, there should be protocols to surface and prioritize
        authoritative information on digital platforms."</i
       >
       This seems like a great suggestion, and related to my personal ideas for
       digital advancement. However, I want to point out that this is a new
       idea, and not something that PBSs of radio and TVs had. People know
       exactly which YouTube channel belongs to PBS, just as much as we know
       which radio frequency is PBS. The problem isn't that we can't tell which
       sources are official, the problem is that people don't trust the official
       sources.
      </li>
     </ul>
    </ul>
    <p>
     <i
      >“Opinion | the Coup We Are Not Talking About.”&nbsp;The New York Times,
      2021.</i
     ><br /><i
      ><a
       href="https://www.nytimes.com/2021/01/29/opinion/sunday/facebook-surveillance-society-technology.html"
       target="_blank"
       >https://www.nytimes.com/2021/01/29/opinion/sunday/facebook-surveillance-society-technology.html</a
      ></i
     >
    </p>
    <ul>
     <li>
      <i
       >"In an information civilization, societies are defined by questions of
       knowledge — how it is distributed, the authority that governs its
       distribution and the power that protects that authority. Who knows? Who
       decides who knows? Who decides who decides who knows? Surveillance
       capitalists now hold the answers to each question, though we never
       elected them to govern. This is the essence of the epistemic coup."</i
      >
     </li>
     <ul>
      <li>
       I took some time to think about why we're in an age where information is
       currency. Previously, materials and labor had value. Capitalism and
       economies of scale have now made materials and labor relatively cheap,
       relative to information.
      </li>
      <li>
       Similarly to how capitalism of materials and labor needs to be checked,
       we should probably have checks on the capitalism of control, information,
       and surveillance. Facebook and Twitter currently run the equivalent of
       the Capitol and the Federal Reserve, but for information. With this
       analogy applied, it easily follows that they perhaps should be regulated.
      </li>
     </ul>
     <li>
      Today I learned: <b>Epistemic injustice</b> — injustice related to
      knowledge.
     </li>
    </ul>
   </div>
  </section>
 </body>
</html>

